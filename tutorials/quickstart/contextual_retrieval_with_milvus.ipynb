{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uXP8f0ONZJ7v"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/tutorials/quickstart/contextual_retrieval_with_milvus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>   <a href=\"https://github.com/milvus-io/bootcamp/blob/master/tutorials/quickstart/contextual_retrieval_with_milvus.ipynb\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/View%20on%20GitHub-555555?style=flat&logo=github&logoColor=white\" alt=\"GitHub Repository\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "KFworYXbZJ7w"
      },
      "source": [
        "# Contextual Retrieval with Milvus\n",
        "![image](https://raw.githubusercontent.com/milvus-io/bootcamp/refs/heads/master/images/contextual_retrieval_with_milvus.png)\n",
        "[Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval) is an advanced retrieval method proposed by Anthropic to address the issue of semantic isolation of chunks, which arises in current Retrieval-Augmented Generation (RAG) solutions. In the current practical RAG paradigm, documents are divided into several chunks, and a vector database is used to search for the query, retrieving the most relevant chunks. An LLM then responds to the query using these retrieved chunks. However, this chunking process can result in the loss of contextual information, making it difficult for the retriever to determine relevance.\n",
        "\n",
        "Contextual Retrieval improves traditional retrieval systems by adding relevant context to each document chunk before embedding or indexing, boosting accuracy and reducing retrieval errors. Combined with techniques like hybrid retrieval and reranking, it enhances Retrieval-Augmented Generation (RAG) systems, especially for large knowledge bases. Additionally, it offers a cost-effective solution when paired with prompt caching, significantly reducing latency and operational costs, with contextualized chunks costing approximately $1.02 per million document tokens. This makes it a scalable and efficient approach for handling large knowledge bases. Anthropicâ€™s solution shows two insightful aspects:\n",
        "- `Document Enhancement`: Query rewriting is a crucial technique in modern information retrieval, often using auxiliary information to make the query more informative. Similarly, to achieve better performance in RAG, preprocessing documents with an LLM (e.g., cleaning the data source, complementing lost information, summarizing, etc.) before indexing can significantly improve the chances of retrieving relevant documents. In other words, this preprocessing step helps bring the documents closer to the queries in terms of relevance.\n",
        "- `Low-Cost Processing by Caching Long Context`: One common concern when using LLMs to process documents is the cost. The KVCache is a popular solution that allows reuse of intermediate results for the same preceding context. While most hosted LLM vendors make this feature transparent to user, Anthropic gives users control over the caching process. When a cache hit occurs, most computations can be saved (this is common when the long context remains the same, but the instruction for each query changes). For more details, click [here](https://www.anthropic.com/news/prompt-caching).\n",
        "\n",
        "In this notebook, we will demonstrate how to perform contextual retrieval using Milvus with an LLM, combining dense-sparse hybrid retrieval and a reranker to create a progressively more powerful retrieval system. The data and experimental setup are based on the [contextual retrieval](https://github.com/anthropics/anthropic-cookbook/blob/main/skills/contextual-embeddings/guide.ipynb).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86GgDvJbZJ7x"
      },
      "source": [
        "## Preparation\n",
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HpyUBntCZJ7x",
        "outputId": "343feb92-1756-4963-8715-39c67a564070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymilvus[model] in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (2.6.5)\r\n",
            "Requirement already satisfied: setuptools>69 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus[model]) (80.9.0)\r\n",
            "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus[model]) (1.76.0)\r\n",
            "Requirement already satisfied: orjson>=3.10.15 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus[model]) (3.11.5)\r\n",
            "Requirement already satisfied: protobuf>=5.27.2 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus[model]) (6.33.2)\r\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus[model]) (1.2.1)\r\n",
            "Requirement already satisfied: pandas>=1.2.4 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus[model]) (2.3.3)\r\n",
            "Requirement already satisfied: pymilvus.model>=0.3.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus[model]) (0.3.2)\r\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2->pymilvus[model]) (4.15.0)\r\n",
            "Requirement already satisfied: numpy>=1.26.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus[model]) (2.4.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus[model]) (2.9.0.post0)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus[model]) (2025.2)\r\n",
            "Requirement already satisfied: tzdata>=2022.7 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus[model]) (2025.3)\r\n",
            "Requirement already satisfied: transformers>=4.36.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus.model>=0.3.0->pymilvus[model]) (4.57.3)\r\n",
            "Requirement already satisfied: onnxruntime in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus.model>=0.3.0->pymilvus[model]) (1.23.2)\r\n",
            "Requirement already satisfied: scipy>=1.10.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pymilvus.model>=0.3.0->pymilvus[model]) (1.16.3)\r\n",
            "Requirement already satisfied: six>=1.5 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus[model]) (1.17.0)\r\n",
            "Requirement already satisfied: filelock in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (3.20.1)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (0.36.0)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (25.0)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (6.0.3)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (2025.11.3)\r\n",
            "Requirement already satisfied: requests in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (2.32.5)\r\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (0.22.1)\r\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (0.7.0)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (2025.12.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]) (25.12.19)\n",
            "Requirement already satisfied: sympy in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from coloredlogs->onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]) (10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from sympy->onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (4.67.1)\n",
            "Requirement already satisfied: anthropic in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (0.71.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (2.12.5)\n",
            "Requirement already satisfied: sniffio in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"pymilvus[model]\"\n",
        "!pip install tqdm\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WycSuZuQZJ7y"
      },
      "source": [
        "> If you are using Google Colab, to enable dependencies just installed, you may need to **restart the runtime** (click on the \"Runtime\" menu at the top of the screen, and select \"Restart session\" from the dropdown menu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUXFjRPLZJ7y"
      },
      "source": [
        "You will need API keys from Cohere, Voyage, and Anthropic to run the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-zIDliAZJ7y"
      },
      "source": [
        "## Download Data\n",
        "The following command will download the example data used in original Anthropic [demo](https://github.com/anthropics/anthropic-cookbook/blob/main/skills/contextual-embeddings/guide.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8Y0zo-0QZJ7z",
        "outputId": "637629ef-f64c-4d4d-9a13-4bd0bbd57001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-24 18:44:51--  https://raw.githubusercontent.com/anthropics/anthropic-cookbook/refs/heads/main/skills/contextual-embeddings/data/codebase_chunks.json\r\n",
            "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-12-24 18:44:51 ERROR 404: Not Found.\n",
            "\n",
            "--2025-12-24 18:44:51--  https://raw.githubusercontent.com/anthropics/anthropic-cookbook/refs/heads/main/skills/contextual-embeddings/data/evaluation_set.jsonl\n",
            "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-12-24 18:44:51 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/anthropics/anthropic-cookbook/refs/heads/main/skills/contextual-embeddings/data/codebase_chunks.json\n",
        "!wget https://raw.githubusercontent.com/anthropics/anthropic-cookbook/refs/heads/main/skills/contextual-embeddings/data/evaluation_set.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvZpeTJhZJ7z"
      },
      "source": [
        "## Define Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzkOXUzSZJ7z"
      },
      "source": [
        "This class is designed to be flexible, allowing you to choose between different retrieval modes based on your needs. By specifying options in the initialization method, you can determine whether to use contextual retrieval, hybrid search (combining dense and sparse retrieval methods), or a reranker for enhanced results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "w4UYjRSwZJ7z"
      },
      "outputs": [],
      "source": [
        "from pymilvus.model.dense import VoyageEmbeddingFunction\n",
        "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
        "from pymilvus.model.reranker import CohereRerankFunction\n",
        "\n",
        "from typing import List, Dict, Any\n",
        "from typing import Callable\n",
        "from pymilvus import (\n",
        "    MilvusClient,\n",
        "    DataType,\n",
        "    AnnSearchRequest,\n",
        "    RRFRanker,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import anthropic\n",
        "import openai\n",
        "\n",
        "class MilvusContextualRetriever:\n",
        "    def __init__(\n",
        "        self,\n",
        "        uri=\"milvus.db\",\n",
        "        collection_name=\"contexual_bgem3\",\n",
        "        dense_embedding_function=None,\n",
        "        use_sparse=False,\n",
        "        sparse_embedding_function=None,\n",
        "        use_contextualize_embedding=False,\n",
        "        anthropic_client=None,\n",
        "        openai_client=None,\n",
        "        use_reranker=False,\n",
        "        rerank_function=None,\n",
        "    ):\n",
        "        self.collection_name = collection_name\n",
        "\n",
        "        # For Milvus-lite, uri is a local path like \"./milvus.db\"\n",
        "        # For Milvus standalone service, uri is like \"http://localhost:19530\"\n",
        "        # For Zilliz Clond, please set `uri` and `token`, which correspond to the [Public Endpoint and API key](https://docs.zilliz.com/docs/on-zilliz-cloud-console#cluster-details) in Zilliz Cloud.\n",
        "        self.client = MilvusClient(uri)\n",
        "\n",
        "        self.embedding_function = dense_embedding_function\n",
        "\n",
        "        self.use_sparse = use_sparse\n",
        "        self.sparse_embedding_function = None\n",
        "\n",
        "        self.use_contextualize_embedding = use_contextualize_embedding\n",
        "        self.anthropic_client = anthropic_clienanthropic_client\n",
        "        self.openai_client = openai.Openai\n",
        "\n",
        "        self.use_reranker = use_reranker\n",
        "        self.rerank_function = rerank_function\n",
        "\n",
        "        if use_sparse is True and sparse_embedding_function:\n",
        "            self.sparse_embedding_function = sparse_embedding_function\n",
        "        elif sparse_embedding_function is False:\n",
        "            raise ValueError(\n",
        "                \"Sparse embedding function cannot be None if use_sparse is False\"\n",
        "            )\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def build_collection(self):\n",
        "        schema = self.client.create_schema(\n",
        "            auto_id=True,\n",
        "            enable_dynamic_field=True,\n",
        "        )\n",
        "        schema.add_field(field_name=\"pk\", datatype=DataType.INT64, is_primary=True)\n",
        "        schema.add_field(\n",
        "            field_name=\"dense_vector\",\n",
        "            datatype=DataType.FLOAT_VECTOR,\n",
        "            dim=self.embedding_function.dim,\n",
        "        )\n",
        "        if self.use_sparse is True:\n",
        "            schema.add_field(\n",
        "                field_name=\"sparse_vector\", datatype=DataType.SPARSE_FLOAT_VECTOR\n",
        "            )\n",
        "\n",
        "        index_params = self.client.prepare_index_params()\n",
        "        index_params.add_index(\n",
        "            field_name=\"dense_vector\", index_type=\"FLAT\", metric_type=\"IP\"\n",
        "        )\n",
        "        if self.use_sparse is True:\n",
        "            index_params.add_index(\n",
        "                field_name=\"sparse_vector\",\n",
        "                index_type=\"SPARSE_INVERTED_INDEX\",\n",
        "                metric_type=\"IP\",\n",
        "            )\n",
        "\n",
        "        self.client.create_collection(\n",
        "            collection_name=self.collection_name,\n",
        "            schema=schema,\n",
        "            index_params=index_params,\n",
        "            enable_dynamic_field=True,\n",
        "        )\n",
        "\n",
        "    def insert_data(self, chunk, metadata):\n",
        "        dense_vec = self.embedding_function([chunk])[0]\n",
        "        if self.use_sparse is True:\n",
        "            sparse_result = self.sparse_embedding_function.encode_documents([chunk])\n",
        "            if type(sparse_result) == dict:\n",
        "                sparse_vec = sparse_result[\"sparse\"][[0]]\n",
        "            else:\n",
        "                sparse_vec = sparse_result[[0]]\n",
        "            self.client.insert(\n",
        "                collection_name=self.collection_name,\n",
        "                data={\n",
        "                    \"dense_vector\": dense_vec,\n",
        "                    \"sparse_vector\": sparse_vec,\n",
        "                    **metadata,\n",
        "                },\n",
        "            )\n",
        "        else:\n",
        "            self.client.insert(\n",
        "                collection_name=self.collection_name,\n",
        "                data={\"dense_vector\": dense_vec, **metadata},\n",
        "            )\n",
        "\n",
        "    def insert_contextualized_data(self, doc, chunk, metadata):\n",
        "        contextualized_text, usage = self.situate_context(doc, chunk)\n",
        "        metadata[\"context\"] = contextualized_text\n",
        "        text_to_embed = f\"{chunk}\\n\\n{contextualized_text}\"\n",
        "        dense_vec = self.embedding_function([text_to_embed])[0]\n",
        "        if self.use_sparse is True:\n",
        "            sparse_vec = self.sparse_embedding_function.encode_documents(\n",
        "                [text_to_embed]\n",
        "            )[\"sparse\"][[0]]\n",
        "            self.client.insert(\n",
        "                collection_name=self.collection_name,\n",
        "                data={\n",
        "                    \"dense_vector\": dense_vec,\n",
        "                    \"sparse_vector\": sparse_vec,\n",
        "                    **metadata,\n",
        "                },\n",
        "            )\n",
        "        else:\n",
        "            self.client.insert(\n",
        "                collection_name=self.collection_name,\n",
        "                data={\"dense_vector\": dense_vec, **metadata},\n",
        "            )\n",
        "\n",
        "    def situate_context(self, doc: str, chunk: str):\n",
        "        DOCUMENT_CONTEXT_PROMPT = \"\"\"\n",
        "        <document>\n",
        "        {doc_content}\n",
        "        </document>\n",
        "        \"\"\"\n",
        "\n",
        "        CHUNK_CONTEXT_PROMPT = \"\"\"\n",
        "        Here is the chunk we want to situate within the whole document\n",
        "        <chunk>\n",
        "        {chunk_content}\n",
        "        </chunk>\n",
        "\n",
        "        Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk.\n",
        "        Answer only with the succinct context and nothing else.\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.self.openai_client. (\n",
        "            model=\"chat\",\n",
        "            base_base_url=\"https://ai.garion.us/v1\",\n",
        "            api_key=\"your-openai-api-key\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.0,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": DOCUMENT_CONTEXT_PROMPT.format(doc_content=doc),\n",
        "                            \"cache_control\": {\n",
        "                                \"type\": \"ephemeral\"\n",
        "                            },  # we will make use of prompt caching for the full documents\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": CHUNK_CONTEXT_PROMPT.format(chunk_content=chunk),\n",
        "                        },\n",
        "                    ],\n",
        "                },\n",
        "            ],\n",
        "            extra_headers={\"anthropic-beta\": \"prompt-caching-2024-07-31\"},\n",
        "        )\n",
        "        return response.content[0].text, response.usage\n",
        "\n",
        "    def search(self, query: str, k: int = 20) -> List[Dict[str, Any]]:\n",
        "        dense_vec = self.embedding_function([query])[0]\n",
        "        if self.use_sparse is True:\n",
        "            sparse_vec = self.sparse_embedding_function.encode_queries([query])[\n",
        "                \"sparse\"\n",
        "            ][[0]]\n",
        "\n",
        "        req_list = []\n",
        "        if self.use_reranker:\n",
        "            k = k * 10\n",
        "        if self.use_sparse is True:\n",
        "            req_list = []\n",
        "            dense_search_param = {\n",
        "                \"data\": [dense_vec],\n",
        "                \"anns_field\": \"dense_vector\",\n",
        "                \"param\": {\"metric_type\": \"IP\"},\n",
        "                \"limit\": k * 2,\n",
        "            }\n",
        "            dense_req = AnnSearchRequest(**dense_search_param)\n",
        "            req_list.append(dense_req)\n",
        "\n",
        "            sparse_search_param = {\n",
        "                \"data\": [sparse_vec],\n",
        "                \"anns_field\": \"sparse_vector\",\n",
        "                \"param\": {\"metric_type\": \"IP\"},\n",
        "                \"limit\": k * 2,\n",
        "            }\n",
        "            sparse_req = AnnSearchRequest(**sparse_search_param)\n",
        "\n",
        "            req_list.append(sparse_req)\n",
        "\n",
        "            docs = self.client.hybrid_search(\n",
        "                self.collection_name,\n",
        "                req_list,\n",
        "                RRFRanker(),\n",
        "                k,\n",
        "                output_fields=[\n",
        "                    \"content\",\n",
        "                    \"original_uuid\",\n",
        "                    \"doc_id\",\n",
        "                    \"chunk_id\",\n",
        "                    \"original_index\",\n",
        "                    \"context\",\n",
        "                ],\n",
        "            )\n",
        "        else:\n",
        "            docs = self.client.search(\n",
        "                self.collection_name,\n",
        "                data=[dense_vec],\n",
        "                anns_field=\"dense_vector\",\n",
        "                limit=k,\n",
        "                output_fields=[\n",
        "                    \"content\",\n",
        "                    \"original_uuid\",\n",
        "                    \"doc_id\",\n",
        "                    \"chunk_id\",\n",
        "                    \"original_index\",\n",
        "                    \"context\",\n",
        "                ],\n",
        "            )\n",
        "        if self.use_reranker and self.use_contextualize_embedding:\n",
        "            reranked_texts = []\n",
        "            reranked_docs = []\n",
        "            for i in range(k):\n",
        "                if self.use_contextualize_embedding:\n",
        "                    reranked_texts.append(\n",
        "                        f\"{docs[0][i]['entity']['content']}\\n\\n{docs[0][i]['entity']['context']}\"\n",
        "                    )\n",
        "                else:\n",
        "                    reranked_texts.append(f\"{docs[0][i]['entity']['content']}\")\n",
        "            results = self.rerank_function(query, reranked_texts)\n",
        "            for result in results:\n",
        "                reranked_docs.append(docs[0][result.index])\n",
        "            docs[0] = reranked_docs\n",
        "        return docs\n",
        "\n",
        "\n",
        "def evaluate_retrieval(\n",
        "    queries: List[Dict[str, Any]], retrieval_function: Callable, db, k: int = 20\n",
        ") -> Dict[str, float]:\n",
        "    total_score = 0\n",
        "    total_queries = len(queries)\n",
        "    for query_item in tqdm(queries, desc=\"Evaluating retrieval\"):\n",
        "        query = query_item[\"query\"]\n",
        "        golden_chunk_uuids = query_item[\"golden_chunk_uuids\"]\n",
        "\n",
        "        # Find all golden chunk contents\n",
        "        golden_contents = []\n",
        "        for doc_uuid, chunk_index in golden_chunk_uuids:\n",
        "            golden_doc = next(\n",
        "                (\n",
        "                    doc\n",
        "                    for doc in query_item[\"golden_documents\"]\n",
        "                    if doc[\"uuid\"] == doc_uuid\n",
        "                ),\n",
        "                None,\n",
        "            )\n",
        "            if not golden_doc:\n",
        "                print(f\"Warning: Golden document not found for UUID {doc_uuid}\")\n",
        "                continue\n",
        "\n",
        "            golden_chunk = next(\n",
        "                (\n",
        "                    chunk\n",
        "                    for chunk in golden_doc[\"chunks\"]\n",
        "                    if chunk[\"index\"] == chunk_index\n",
        "                ),\n",
        "                None,\n",
        "            )\n",
        "            if not golden_chunk:\n",
        "                print(\n",
        "                    f\"Warning: Golden chunk not found for index {chunk_index} in document {doc_uuid}\"\n",
        "                )\n",
        "                continue\n",
        "\n",
        "            golden_contents.append(golden_chunk[\"content\"].strip())\n",
        "\n",
        "        if not golden_contents:\n",
        "            print(f\"Warning: No golden contents found for query: {query}\")\n",
        "            continue\n",
        "\n",
        "        retrieved_docs = retrieval_function(query, db, k=k)\n",
        "\n",
        "        # Count how many golden chunks are in the top k retrieved documents\n",
        "        chunks_found = 0\n",
        "        for golden_content in golden_contents:\n",
        "            for doc in retrieved_docs[0][:k]:\n",
        "                retrieved_content = doc[\"entity\"][\"content\"].strip()\n",
        "                if retrieved_content == golden_content:\n",
        "                    chunks_found += 1\n",
        "                    break\n",
        "\n",
        "        query_score = chunks_found / len(golden_contents)\n",
        "        total_score += query_score\n",
        "\n",
        "    average_score = total_score / total_queries\n",
        "    pass_at_n = average_score * 100\n",
        "    return {\n",
        "        \"pass_at_n\": pass_at_n,\n",
        "        \"average_score\": average_score,\n",
        "        \"total_queries\": total_queries,\n",
        "    }\n",
        "\n",
        "\n",
        "def retrieve_base(query: str, db, k: int = 20) -> List[Dict[str, Any]]:\n",
        "    return db.search(query, k=k)\n",
        "\n",
        "\n",
        "def load_jsonl(file_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load JSONL file and return a list of dictionaries.\"\"\"\n",
        "    with open(file_path, \"r\") as file:\n",
        "        return [json.loads(line) for line in file]\n",
        "\n",
        "\n",
        "def evaluate_db(db, original_jsonl_path: str, k):\n",
        "    # Load the original JSONL data for queries and ground truth\n",
        "    original_data = load_jsonl(original_jsonl_path)\n",
        "\n",
        "    # Evaluate retrieval\n",
        "    results = evaluate_retrieval(original_data, retrieve_base, db, k)\n",
        "    print(f\"Pass@{k}: {results['pass_at_n']:.2f}%\")\n",
        "    print(f\"Total Score: {results['average_score']}\")\n",
        "    print(f\"Total queries: {results['total_queries']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwftjImoZJ71"
      },
      "source": [
        "Now you need to initialize these models for the following experiments. You can easily switch to other models using the PyMilvus model library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cPpf6NmSZJ72",
        "outputId": "114484a3-6e24-4f58-f6a9-06ba60e32e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# dense_ef = VoyageEmbeddingFunction(api_key=\"your-voyage-api-key\", model_name=\"voyage-2\")\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dense_ef = \u001b[43mmodel\u001b[49m.dense.OpenAIEmbeddingFunction(\n\u001b[32m      5\u001b[39m       model_name=\u001b[33m'\u001b[39m\u001b[33membed\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# Specify the model name\u001b[39;00m\n\u001b[32m      6\u001b[39m       api_key=\u001b[33m'\u001b[39m\u001b[33mYOUR_API_KEY\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# Provide your OpenAI API key\u001b[39;00m\n\u001b[32m      7\u001b[39m       dimensions=\u001b[32m2048\u001b[39m, \u001b[38;5;66;03m# Set the embedding dimensionality\u001b[39;00m\n\u001b[32m      8\u001b[39m       base_url = \u001b[33m'\u001b[39m\u001b[33mhttp://garion.us:8005/v1\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;66;03m# Set the base URL for the OpenAI API\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m sparse_ef = BGEM3EmbeddingFunction()\n\u001b[32m     12\u001b[39m cohere_rf = CohereRerankFunction(api_key=\u001b[33m\"\u001b[39m\u001b[33myour-cohere-api-key\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# dense_ef = VoyageEmbeddingFunction(api_key=\"your-voyage-api-key\", model_name=\"voyage-2\")\n",
        "from pymilvus import model\n",
        "import openai\n",
        "\n",
        "dense_ef = model.dense.OpenAIEmbeddingFunction(\n",
        "      model_name='embed', # Specify the model name\n",
        "      api_key='YOUR_API_KEY', # Provide your OpenAI API key\n",
        "      dimensions=2048, # Set the embedding dimensionality\n",
        "      base_url = 'http://garion.us:8005/v1' # Set the base URL for the OpenAI API\n",
        ")\n",
        "\n",
        "sparse_ef = BGEM3EmbeddingFunction()\n",
        "cohere_rf = CohereRerankFunction(api_key=\"your-cohere-api-key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9_alPLm-ZJ72"
      },
      "outputs": [],
      "source": [
        "path = \"codebase_chunks.json\"\n",
        "with open(path, \"r\") as f:\n",
        "    dataset = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MHeCnvJZJ72"
      },
      "source": [
        "## Experiment I: Standard Retrieval\n",
        "Standard retrieval uses only dense embeddings to retrieve related documents. In this experiment, we will use Pass@5 to reproduce the results from the original repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QnZbS-xEZJ73",
        "outputId": "d978644f-53cf-46cb-d9b0-c2da3492ff83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-24 18:44:53,656 [ERROR][handler]: RPC error: [create_collection], <MilvusException: (code=1100, message=create duplicate collection with different parameters, collection standard: invalid parameter)>, <Time:{'RPC start': '2025-12-24 18:44:53.655259', 'RPC error': '2025-12-24 18:44:53.656253'}>\n",
            "Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py\", line 263, in handler\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py\", line 322, in handler\n",
            "    return func(self, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py\", line 196, in handler\n",
            "    raise e from e\n",
            "  File \"/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py\", line 166, in handler\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py\", line 381, in create_collection\n",
            "    check_status(status)\n",
            "  File \"/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/utils.py\", line 66, in check_status\n",
            "    raise MilvusException(status.code, status.reason, status.error_code)\n",
            "pymilvus.exceptions.MilvusException: <MilvusException: (code=1100, message=create duplicate collection with different parameters, collection standard: invalid parameter)>\n",
            " (decorators.py:267)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MilvusException",
          "evalue": "<MilvusException: (code=1100, message=create duplicate collection with different parameters, collection standard: invalid parameter)>",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMilvusException\u001b[39m                           Traceback (most recent call last)",
            "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m standard_retriever = MilvusContextualRetriever(\n\u001b[32m      2\u001b[39m     uri=\u001b[33m\"\u001b[39m\u001b[33mstandard.db\u001b[39m\u001b[33m\"\u001b[39m, collection_name=\u001b[33m\"\u001b[39m\u001b[33mstandard\u001b[39m\u001b[33m\"\u001b[39m, dense_embedding_function=dense_ef\n\u001b[32m      3\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mstandard_retriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m dataset:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mMilvusContextualRetriever.build_collection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m     index_params.add_index(\n\u001b[32m     80\u001b[39m         field_name=\u001b[33m\"\u001b[39m\u001b[33msparse_vector\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m         index_type=\u001b[33m\"\u001b[39m\u001b[33mSPARSE_INVERTED_INDEX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     82\u001b[39m         metric_type=\u001b[33m\"\u001b[39m\u001b[33mIP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_dynamic_field\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/milvus_client/milvus_client.py:101\u001b[39m, in \u001b[36mMilvusClient.create_collection\u001b[39m\u001b[34m(self, collection_name, dimension, primary_field_name, id_type, vector_field_name, metric_type, auto_id, timeout, schema, index_params, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_create_collection(\n\u001b[32m     90\u001b[39m         collection_name,\n\u001b[32m     91\u001b[39m         dimension,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m         **kwargs,\n\u001b[32m     99\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_collection_with_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/milvus_client/milvus_client.py:843\u001b[39m, in \u001b[36mMilvusClient._create_collection_with_schema\u001b[39m\u001b[34m(self, collection_name, schema, index_params, timeout, **kwargs)\u001b[39m\n\u001b[32m    842\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mconsistency_level\u001b[39m\u001b[33m\"\u001b[39m] = DEFAULT_CONSISTENCY_LEVEL\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_params:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:271\u001b[39m, in \u001b[36merror_handler.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m     LOGGER.error(\n\u001b[32m    268\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    269\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraceback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtb_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.FutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:263\u001b[39m, in \u001b[36merror_handler.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m     record_dict[\u001b[33m\"\u001b[39m\u001b[33mRPC start\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(datetime.datetime.now())\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:322\u001b[39m, in \u001b[36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_onetime_loglevel(level)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:196\u001b[39m, in \u001b[36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:166\u001b[39m, in \u001b[36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py:381\u001b[39m, in \u001b[36mGrpcHandler.create_collection\u001b[39m\u001b[34m(self, collection_name, fields, timeout, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m status = rf.result()\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/utils.py:66\u001b[39m, in \u001b[36mcheck_status\u001b[39m\u001b[34m(status)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status.code != \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status.error_code != \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status.code, status.reason, status.error_code)\n",
            "\u001b[31mMilvusException\u001b[39m: <MilvusException: (code=1100, message=create duplicate collection with different parameters, collection standard: invalid parameter)>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mMilvusException\u001b[39m                           Traceback (most recent call last)",
            "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m standard_retriever = MilvusContextualRetriever(\n\u001b[32m      2\u001b[39m     uri=\u001b[33m\"\u001b[39m\u001b[33mstandard.db\u001b[39m\u001b[33m\"\u001b[39m, collection_name=\u001b[33m\"\u001b[39m\u001b[33mstandard\u001b[39m\u001b[33m\"\u001b[39m, dense_embedding_function=dense_ef\n\u001b[32m      3\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mstandard_retriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m dataset:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mMilvusContextualRetriever.build_collection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m     index_params.add_index(\n\u001b[32m     80\u001b[39m         field_name=\u001b[33m\"\u001b[39m\u001b[33msparse_vector\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m         index_type=\u001b[33m\"\u001b[39m\u001b[33mSPARSE_INVERTED_INDEX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     82\u001b[39m         metric_type=\u001b[33m\"\u001b[39m\u001b[33mIP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_dynamic_field\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/milvus_client/milvus_client.py:101\u001b[39m, in \u001b[36mMilvusClient.create_collection\u001b[39m\u001b[34m(self, collection_name, dimension, primary_field_name, id_type, vector_field_name, metric_type, auto_id, timeout, schema, index_params, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_create_collection(\n\u001b[32m     90\u001b[39m         collection_name,\n\u001b[32m     91\u001b[39m         dimension,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m         **kwargs,\n\u001b[32m     99\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_collection_with_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/milvus_client/milvus_client.py:843\u001b[39m, in \u001b[36mMilvusClient._create_collection_with_schema\u001b[39m\u001b[34m(self, collection_name, schema, index_params, timeout, **kwargs)\u001b[39m\n\u001b[32m    842\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mconsistency_level\u001b[39m\u001b[33m\"\u001b[39m] = DEFAULT_CONSISTENCY_LEVEL\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_params:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:271\u001b[39m, in \u001b[36merror_handler.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m     LOGGER.error(\n\u001b[32m    268\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    269\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraceback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtb_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.FutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:263\u001b[39m, in \u001b[36merror_handler.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m     record_dict[\u001b[33m\"\u001b[39m\u001b[33mRPC start\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(datetime.datetime.now())\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:322\u001b[39m, in \u001b[36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_onetime_loglevel(level)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:196\u001b[39m, in \u001b[36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:166\u001b[39m, in \u001b[36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py:381\u001b[39m, in \u001b[36mGrpcHandler.create_collection\u001b[39m\u001b[34m(self, collection_name, fields, timeout, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m status = rf.result()\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/utils.py:66\u001b[39m, in \u001b[36mcheck_status\u001b[39m\u001b[34m(status)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status.code != \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status.error_code != \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status.code, status.reason, status.error_code)\n",
            "\u001b[31mMilvusException\u001b[39m: <MilvusException: (code=1100, message=create duplicate collection with different parameters, collection standard: invalid parameter)>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mMilvusException\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m standard_retriever = MilvusContextualRetriever(\n\u001b[32m      2\u001b[39m     uri=\u001b[33m\"\u001b[39m\u001b[33mstandard.db\u001b[39m\u001b[33m\"\u001b[39m, collection_name=\u001b[33m\"\u001b[39m\u001b[33mstandard\u001b[39m\u001b[33m\"\u001b[39m, dense_embedding_function=dense_ef\n\u001b[32m      3\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mstandard_retriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[32m      7\u001b[39m     doc_content = doc[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mMilvusContextualRetriever.build_collection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     79\u001b[39m     index_params.add_index(\n\u001b[32m     80\u001b[39m         field_name=\u001b[33m\"\u001b[39m\u001b[33msparse_vector\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m         index_type=\u001b[33m\"\u001b[39m\u001b[33mSPARSE_INVERTED_INDEX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     82\u001b[39m         metric_type=\u001b[33m\"\u001b[39m\u001b[33mIP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_dynamic_field\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/milvus_client/milvus_client.py:101\u001b[39m, in \u001b[36mMilvusClient.create_collection\u001b[39m\u001b[34m(self, collection_name, dimension, primary_field_name, id_type, vector_field_name, metric_type, auto_id, timeout, schema, index_params, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_create_collection(\n\u001b[32m     90\u001b[39m         collection_name,\n\u001b[32m     91\u001b[39m         dimension,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m         **kwargs,\n\u001b[32m     99\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_collection_with_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/milvus_client/milvus_client.py:843\u001b[39m, in \u001b[36mMilvusClient._create_collection_with_schema\u001b[39m\u001b[34m(self, collection_name, schema, index_params, timeout, **kwargs)\u001b[39m\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mconsistency_level\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    842\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mconsistency_level\u001b[39m\u001b[33m\"\u001b[39m] = DEFAULT_CONSISTENCY_LEVEL\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_params:\n\u001b[32m    846\u001b[39m     \u001b[38;5;28mself\u001b[39m.create_index(collection_name, index_params, timeout=timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:271\u001b[39m, in \u001b[36merror_handler.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    266\u001b[39m     tb_str = traceback.format_exc()\n\u001b[32m    267\u001b[39m     LOGGER.error(\n\u001b[32m    268\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    269\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraceback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtb_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.FutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    273\u001b[39m     record_dict[\u001b[33m\"\u001b[39m\u001b[33mgRPC timeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(datetime.datetime.now())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:263\u001b[39m, in \u001b[36merror_handler.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    262\u001b[39m     record_dict[\u001b[33m\"\u001b[39m\u001b[33mRPC start\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(datetime.datetime.now())\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    265\u001b[39m     record_dict[\u001b[33m\"\u001b[39m\u001b[33mRPC error\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(datetime.datetime.now())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:322\u001b[39m, in \u001b[36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_onetime_loglevel(level)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:196\u001b[39m, in \u001b[36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    194\u001b[39m         back_off = \u001b[38;5;28mmin\u001b[39m(back_off * back_off_multiplier, max_back_off)\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/decorators.py:166\u001b[39m, in \u001b[36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    168\u001b[39m         \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m e.code() \u001b[38;5;129;01min\u001b[39;00m IGNORE_RETRY_CODES:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py:381\u001b[39m, in \u001b[36mGrpcHandler.create_collection\u001b[39m\u001b[34m(self, collection_name, fields, timeout, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rf\n\u001b[32m    380\u001b[39m status = rf.result()\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.cache/uv/builds-v0/.tmp240B8K/lib/python3.12/site-packages/pymilvus/client/utils.py:66\u001b[39m, in \u001b[36mcheck_status\u001b[39m\u001b[34m(status)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_status\u001b[39m(status: Status):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status.code != \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status.error_code != \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status.code, status.reason, status.error_code)\n",
            "\u001b[31mMilvusException\u001b[39m: <MilvusException: (code=1100, message=create duplicate collection with different parameters, collection standard: invalid parameter)>"
          ]
        }
      ],
      "source": [
        "standard_retriever = MilvusContextualRetriever(\n",
        "    uri=\"standard.db\", collection_name=\"standard\", dense_embedding_function=dense_ef\n",
        ")\n",
        "\n",
        "standard_retriever.build_collection()\n",
        "for doc in dataset:\n",
        "    doc_content = doc[\"content\"]\n",
        "    for chunk in doc[\"chunks\"]:\n",
        "        metadata = {\n",
        "            \"doc_id\": doc[\"doc_id\"],\n",
        "            \"original_uuid\": doc[\"original_uuid\"],\n",
        "            \"chunk_id\": chunk[\"chunk_id\"],\n",
        "            \"original_index\": chunk[\"original_index\"],\n",
        "            \"content\": chunk[\"content\"],\n",
        "        }\n",
        "        chunk_content = chunk[\"content\"]\n",
        "        standard_retriever.insert_data(chunk_content, metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YymKVbUqZJ73"
      },
      "outputs": [],
      "source": [
        "evaluate_db(standard_retriever, \"evaluation_set.jsonl\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ppUg2pZJ73"
      },
      "source": [
        "## Experiment II: Hybrid Retrieval\n",
        "Now that we've obtained promising results with the Voyage embedding, we will move on to performing hybrid retrieval using the BGE-M3 model which generates powerful sparse embeddings. The results from dense retrieval and sparse retrieval will be combined using the Reciprocal Rank Fusion (RRF) method to produce a hybrid result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh9pzpdeZJ73"
      },
      "outputs": [],
      "source": [
        "hybrid_retriever = MilvusContextualRetriever(\n",
        "    uri=\"hybrid.db\",\n",
        "    collection_name=\"hybrid\",\n",
        "    dense_embedding_function=dense_ef,\n",
        "    use_sparse=True,\n",
        "    sparse_embedding_function=sparse_ef,\n",
        ")\n",
        "\n",
        "hybrid_retriever.build_collection()\n",
        "for doc in dataset:\n",
        "    doc_content = doc[\"content\"]\n",
        "    for chunk in doc[\"chunks\"]:\n",
        "        metadata = {\n",
        "            \"doc_id\": doc[\"doc_id\"],\n",
        "            \"original_uuid\": doc[\"original_uuid\"],\n",
        "            \"chunk_id\": chunk[\"chunk_id\"],\n",
        "            \"original_index\": chunk[\"original_index\"],\n",
        "            \"content\": chunk[\"content\"],\n",
        "        }\n",
        "        chunk_content = chunk[\"content\"]\n",
        "        hybrid_retriever.insert_data(chunk_content, metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wosLUi2nZJ73"
      },
      "outputs": [],
      "source": [
        "evaluate_db(hybrid_retriever, \"evaluation_set.jsonl\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwDf-cbjZJ74"
      },
      "source": [
        "## Experiment III: Contextual Retrieval\n",
        "Hybrid retrieval shows an improvement, but the results can be further enhanced by applying a contextual retrieval method. To achieve this, we will use Anthropic's language model to prepend the context from whole document for each chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxaNIuKrZJ74"
      },
      "outputs": [],
      "source": [
        "anthropic_client = anthropic.Anthropic(\n",
        "    api_key=\"your-anthropic-api-key\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X09E0Q9HZJ74"
      },
      "outputs": [],
      "source": [
        "contextual_retriever = MilvusContextualRetriever(\n",
        "    uri=\"contextual.db\",\n",
        "    collection_name=\"contextual\",\n",
        "    dense_embedding_function=dense_ef,\n",
        "    use_sparse=True,\n",
        "    sparse_embedding_function=sparse_ef,\n",
        "    use_contextualize_embedding=True,\n",
        "    anthropic_client=anthropic_client,\n",
        ")\n",
        "\n",
        "contextual_retriever.build_collection()\n",
        "for doc in dataset:\n",
        "    doc_content = doc[\"content\"]\n",
        "    for chunk in doc[\"chunks\"]:\n",
        "        metadata = {\n",
        "            \"doc_id\": doc[\"doc_id\"],\n",
        "            \"original_uuid\": doc[\"original_uuid\"],\n",
        "            \"chunk_id\": chunk[\"chunk_id\"],\n",
        "            \"original_index\": chunk[\"original_index\"],\n",
        "            \"content\": chunk[\"content\"],\n",
        "        }\n",
        "        chunk_content = chunk[\"content\"]\n",
        "        contextual_retriever.insert_contextualized_data(\n",
        "            doc_content, chunk_content, metadata\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7usuZV4oZJ74"
      },
      "outputs": [],
      "source": [
        "evaluate_db(contextual_retriever, \"evaluation_set.jsonl\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKFF7SqbZJ74"
      },
      "source": [
        "## Experiment IV: Contextual Retrieval with Reranker\n",
        "The results can be further improved by adding a Cohere reranker. Without initializing a new retriever with reranker separately, we can simply configure the existing retriever to use the reranker for enhanced performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlQ_YxbqZJ74"
      },
      "outputs": [],
      "source": [
        "contextual_retriever.use_reranker = True\n",
        "contextual_retriever.rerank_function = cohere_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH0s2UK1ZJ74"
      },
      "outputs": [],
      "source": [
        "evaluate_db(contextual_retriever, \"evaluation_set.jsonl\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "its4uH0BZJ74"
      },
      "source": [
        "We have demonstrated several methods to improve retrieval performance. With more ad-hoc design tailored to the scenario, contextual retrieval shows significant potential to preprocess documents at a low cost, leading to a better RAG system."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}